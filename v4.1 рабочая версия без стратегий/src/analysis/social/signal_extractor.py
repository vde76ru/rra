"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π
"""
import re
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import numpy as np
from collections import defaultdict

from ...logging.smart_logger import SmartLogger
from ...core.database import SessionLocal
from .twitter_monitor import TwitterMonitor
from .reddit_monitor import RedditMonitor

logger = SmartLogger(__name__)


class SocialSignalExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Å–æ—Ü—Å–µ—Ç–µ–π"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
    SIGNAL_PATTERNS = {
        'buy': [
            r'(?i)\b(buy|long|–∫—É–ø–∏—Ç—å|–ª–æ–Ω–≥)\s+(\w+)',
            r'(?i)(\w+)\s+(to the moon|üöÄ|üìà)',
            r'(?i)(\w+)\s+(bullish|–±—ã—á–∏–π)',
            r'(?i)(accumulate|–Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å)\s+(\w+)'
        ],
        'sell': [
            r'(?i)\b(sell|short|–ø—Ä–æ–¥–∞—Ç—å|—à–æ—Ä—Ç)\s+(\w+)',
            r'(?i)(\w+)\s+(crash|dump|üìâ)',
            r'(?i)(\w+)\s+(bearish|–º–µ–¥–≤–µ–∂–∏–π)',
            r'(?i)(exit|–≤—ã—Ö–æ–¥)\s+(\w+)'
        ],
        'price_target': [
            r'(?i)(\w+)\s+(?:target|—Ü–µ–ª—å)\s*[:=]?\s*\$?(\d+\.?\d*)',
            r'(?i)(\w+)\s+to\s+\$?(\d+\.?\d*)'
        ]
    }
    
    # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    CRYPTO_SYMBOLS = {
        'BTC': ['bitcoin', 'btc', '–±–∏—Ç–∫–æ–∏–Ω'],
        'ETH': ['ethereum', 'eth', '—ç—Ñ–∏—Ä', '—ç—Ñ–∏—Ä–∏—É–º'],
        'BNB': ['binance', 'bnb', '–±–∏–Ω–∞–Ω—Å'],
        'SOL': ['solana', 'sol', '—Å–æ–ª–∞–Ω–∞'],
        'XRP': ['ripple', 'xrp', '—Ä–∏–ø–ª'],
        # –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    }
    
    def __init__(self):
        self.twitter_monitor = TwitterMonitor()
        self.reddit_monitor = RedditMonitor()
        self.signal_cache = defaultdict(list)
        self.influencer_scores = {}
        
    async def get_sentiment(self, symbol: str) -> float:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—â–∏–π sentiment –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ—Å—Ç—ã
        twitter_posts = await self.twitter_monitor.get_recent_posts(symbol, hours=4)
        reddit_posts = await self.reddit_monitor.get_recent_posts(symbol, hours=4)
        
        all_posts = twitter_posts + reddit_posts
        
        if not all_posts:
            return 0.0
        
        # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π sentiment
        total_sentiment = 0
        total_weight = 0
        
        for post in all_posts:
            weight = self._calculate_post_weight(post)
            sentiment = post.get('sentiment', 0)
            
            total_sentiment += sentiment * weight
            total_weight += weight
        
        if total_weight == 0:
            return 0.0
        
        return total_sentiment / total_weight
    
    async def extract_signals(self, timeframe_hours: int = 1) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        signals = []
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã
        twitter_posts = await self.twitter_monitor.get_recent_posts(hours=timeframe_hours)
        reddit_posts = await self.reddit_monitor.get_recent_posts(hours=timeframe_hours)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞
        for post in twitter_posts + reddit_posts:
            extracted = self._extract_signals_from_post(post)
            signals.extend(extracted)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        aggregated_signals = self._aggregate_signals(signals)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        quality_signals = []
        for signal in aggregated_signals:
            quality = self._evaluate_signal_quality(signal)
            if quality > 0.6:
                signal['quality_score'] = quality
                quality_signals.append(signal)
        
        logger.info(
            f"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(quality_signals)} –∏–∑ {len(signals)} —Å—ã—Ä—ã—Ö",
            category='social',
            quality_threshold=0.6
        )
        
        return quality_signals
    
    def _extract_signals_from_post(self, post: Dict) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞"""
        signals = []
        text = post.get('content', '')
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∫—É–ø–∫–∏
        for pattern in self.SIGNAL_PATTERNS['buy']:
            matches = re.findall(pattern, text)
            for match in matches:
                symbol = self._normalize_symbol(match[-1] if isinstance(match, tuple) else match)
                if symbol:
                    signals.append({
                        'type': 'buy',
                        'symbol': symbol,
                        'source': post['platform'],
                        'author': post['author'],
                        'timestamp': post['created_at'],
                        'text': text[:200],
                        'engagement': post.get('engagement_score', 0),
                        'author_followers': post.get('author_followers', 0)
                    })
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–¥–∞–∂–∏
        for pattern in self.SIGNAL_PATTERNS['sell']:
            matches = re.findall(pattern, text)
            for match in matches:
                symbol = self._normalize_symbol(match[-1] if isinstance(match, tuple) else match)
                if symbol:
                    signals.append({
                        'type': 'sell',
                        'symbol': symbol,
                        'source': post['platform'],
                        'author': post['author'],
                        'timestamp': post['created_at'],
                        'text': text[:200],
                        'engagement': post.get('engagement_score', 0),
                        'author_followers': post.get('author_followers', 0)
                    })
        
        # –ò—â–µ–º —Ü–µ–Ω–æ–≤—ã–µ —Ü–µ–ª–∏
        for pattern in self.SIGNAL_PATTERNS['price_target']:
            matches = re.findall(pattern, text)
            for match in matches:
                symbol = self._normalize_symbol(match[0])
                if symbol:
                    try:
                        target_price = float(match[1])
                        signals.append({
                            'type': 'price_target',
                            'symbol': symbol,
                            'target': target_price,
                            'source': post['platform'],
                            'author': post['author'],
                            'timestamp': post['created_at'],
                            'text': text[:200]
                        })
                    except ValueError:
                        pass
        
        return signals
    
    def _normalize_symbol(self, text: str) -> Optional[str]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å–∏–º–≤–æ–ª –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã"""
        text = text.upper().strip()
        
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if text in self.CRYPTO_SYMBOLS:
            return text
        
        # –ü–æ–∏—Å–∫ –ø–æ –∞–ª–∏–∞—Å–∞–º
        for symbol, aliases in self.CRYPTO_SYMBOLS.items():
            if text.lower() in aliases:
                return symbol
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω—ã–π —Ç–∏–∫–µ—Ä (3-5 –±—É–∫–≤)
        if re.match(r'^[A-Z]{3,5}$', text):
            return text
        
        return None
    
    def _aggregate_signals(self, signals: List[Dict]) -> List[Dict]:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Å–∏–≥–Ω–∞–ª—ã"""
        aggregated = defaultdict(lambda: {
            'count': 0,
            'buy_count': 0,
            'sell_count': 0,
            'authors': set(),
            'sources': defaultdict(int),
            'total_engagement': 0,
            'total_followers': 0,
            'timestamps': []
        })
        
        for signal in signals:
            symbol = signal['symbol']
            agg = aggregated[symbol]
            
            agg['count'] += 1
            if signal['type'] == 'buy':
                agg['buy_count'] += 1
            elif signal['type'] == 'sell':
                agg['sell_count'] += 1
            
            agg['authors'].add(signal['author'])
            agg['sources'][signal['source']] += 1
            agg['total_engagement'] += signal.get('engagement', 0)
            agg['total_followers'] += signal.get('author_followers', 0)
            agg['timestamps'].append(signal['timestamp'])
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
        result = []
        for symbol, data in aggregated.items():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            if data['buy_count'] > data['sell_count'] * 1.5:
                direction = 'buy'
                confidence = data['buy_count'] / data['count']
            elif data['sell_count'] > data['buy_count'] * 1.5:
                direction = 'sell'
                confidence = data['sell_count'] / data['count']
            else:
                continue  # –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
            
            result.append({
                'symbol': symbol,
                'direction': direction,
                'confidence': confidence,
                'mentions': data['count'],
                'unique_authors': len(data['authors']),
                'sources': dict(data['sources']),
                'avg_engagement': data['total_engagement'] / data['count'],
                'avg_followers': data['total_followers'] / data['count'],
                'first_mention': min(data['timestamps']),
                'last_mention': max(data['timestamps'])
            })
        
        return result
    
    def _evaluate_signal_quality(self, signal: Dict) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞"""
        score = 0.5  # –ë–∞–∑–æ–≤—ã–π —Å—á–µ—Ç
        
        # –§–∞–∫—Ç–æ—Ä—ã –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        if signal['mentions'] > 10:
            score += 0.1
        if signal['unique_authors'] > 5:
            score += 0.1
        if signal['avg_followers'] > 10000:
            score += 0.15
        if signal['avg_engagement'] > 100:
            score += 0.1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ pump & dump –ø—Ä–∏–∑–Ω–∞–∫–∏
        time_span = (signal['last_mention'] - signal['first_mention']).total_seconds() / 3600
        mention_rate = signal['mentions'] / max(time_span, 0.1)
        
        if mention_rate > 50:  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∑–∞ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤—Ä–µ–º—è
            score -= 0.3
        
        # –î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        source_diversity = len(signal['sources']) / signal['mentions']
        score += source_diversity * 0.1
        
        # –£—á–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –∞–≤—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        # TODO: –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        
        return min(max(score, 0), 1)
    
    def _calculate_post_weight(self, post: Dict) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–µ—Å –ø–æ—Å—Ç–∞ –¥–ª—è sentiment –∞–Ω–∞–ª–∏–∑–∞"""
        weight = 1.0
        
        # –í–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
        followers = post.get('author_followers', 0)
        if followers > 100000:
            weight *= 2.0
        elif followers > 10000:
            weight *= 1.5
        elif followers < 1000:
            weight *= 0.5
        
        # –í–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
        engagement = post.get('engagement_score', 0)
        if engagement > 1000:
            weight *= 1.5
        elif engagement > 100:
            weight *= 1.2
        
        # –í–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        if post['platform'] == 'twitter' and post.get('is_verified'):
            weight *= 1.3
        
        # –°–≤–µ–∂–µ—Å—Ç—å
        age_hours = (datetime.utcnow() - post['created_at']).total_seconds() / 3600
        freshness_factor = max(0.5, 1 - age_hours / 24)
        weight *= freshness_factor
        
        return weight
    
    async def detect_pump_dump(self, symbol: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ pump & dump"""
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
        history = await self._get_mention_history(symbol, hours=24)
        
        if len(history) < 10:
            return {'risk': 'low', 'confidence': 0.3}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
        timestamps = [h['timestamp'] for h in history]
        mention_counts = [h['count'] for h in history]
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
        recent_rate = np.mean(mention_counts[-3:])
        historical_rate = np.mean(mention_counts[:-3])
        
        if historical_rate == 0:
            growth_rate = float('inf')
        else:
            growth_rate = recent_rate / historical_rate
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ pump & dump
        indicators = {
            'sudden_spike': growth_rate > 5,
            'concentrated_source': self._check_source_concentration(history),
            'new_accounts': self._check_new_accounts(history),
            'repetitive_content': self._check_content_similarity(history)
        }
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
        risk_score = sum(1 for ind in indicators.values() if ind) / len(indicators)
        
        if risk_score > 0.7:
            risk_level = 'high'
        elif risk_score > 0.4:
            risk_level = 'medium'
        else:
            risk_level = 'low'
        
        return {
            'risk': risk_level,
            'confidence': min(len(history) / 100, 1),
            'growth_rate': growth_rate,
            'indicators': indicators
        }
    
    async def _get_mention_history(self, symbol: str, hours: int) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å–∏–º–≤–æ–ª–∞"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –ë–î —Å –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π –ø–æ —á–∞—Å–∞–º
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞
        return []
    
    def _check_source_concentration(self, history: List[Dict]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        all_authors = []
        for h in history:
            all_authors.extend(h.get('authors', []))
        
        if not all_authors:
            return False
        
        # –ï—Å–ª–∏ > 50% –æ—Ç –æ–¥–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        author_counts = defaultdict(int)
        for author in all_authors:
            author_counts[author] += 1
        
        max_count = max(author_counts.values())
        return max_count / len(all_authors) > 0.5
    
    def _check_new_accounts(self, history: List[Dict]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ–ª—é –Ω–æ–≤—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False
        return False
    
    def _check_content_similarity(self, history: List[Dict]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤
        # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False
        return False