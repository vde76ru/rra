"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π Trainer –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ ML –º–æ–¥–µ–ª–µ–π
–§–∞–π–ª: src/ml/training/trainer.py

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π
"""
import asyncio
import numpy as np
import pandas as pd
import pickle
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix
)
from sklearn.ensemble import RandomForestClassifier
import json
from pathlib import Path

from sqlalchemy.orm import Session
from ...core.database import SessionLocal
from ...core.models import Trade, Signal
from ...core.config import Config
from ...logging.smart_logger import SmartLogger
from ..features.feature_engineering import FeatureEngineer
from ..models.classifier import DirectionClassifier


class EnsembleModel:
    """
    –ê–Ω—Å–∞–º–±–ª—å ML –º–æ–¥–µ–ª–µ–π —Å –≤–∑–≤–µ—à–µ–Ω–Ω—ã–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º
    """
    
    def __init__(self, models: Dict, weights: Optional[List[float]] = None, name: str = "ensemble"):
        self.models = models
        self.weights = weights or [1/len(models)] * len(models)
        self.name = name
        self.feature_columns = None
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
        total_weight = sum(self.weights)
        self.weights = [w / total_weight for w in self.weights]
    
    def predict_proba(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å –≤–∑–≤–µ—à–µ–Ω–Ω—ã–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º"""
        predictions = []
        model_names = list(self.models.keys())
        
        for i, (name, model) in enumerate(self.models.items()):
            try:
                if hasattr(model, 'predict_proba'):
                    pred = model.predict_proba(X)
                else:
                    # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ predict_proba —Å–æ–∑–¥–∞–µ–º one-hot
                    pred_classes = model.predict(X)
                    unique_classes = np.unique(pred_classes)
                    pred = np.zeros((len(pred_classes), len(unique_classes)))
                    for j, cls in enumerate(unique_classes):
                        pred[pred_classes == cls, j] = 1.0
                
                predictions.append(pred * self.weights[i])
            except Exception as e:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Å–ª–æ–º–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—ë
                continue
        
        if not predictions:
            raise ValueError("–í—Å–µ –º–æ–¥–µ–ª–∏ –≤ –∞–Ω—Å–∞–º–±–ª–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        
        # –°—É–º–º–∏—Ä—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        ensemble_pred = np.sum(predictions, axis=0)
        return ensemble_pred
    
    def predict(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤"""
        proba = self.predict_proba(X)
        return np.argmax(proba, axis=1) - 1  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º -1, 0, 1
    
    def get_confidence(self, X):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        proba = self.predict_proba(X)
        return np.max(proba, axis=1)


class MLTrainer:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π
    """
    
    def __init__(self):
        self.logger = SmartLogger("ml.trainer")
        self.feature_engineer = FeatureEngineer()
        self.models = {}
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.reports_dir = Path("reports/ml")
        self.models_dir = Path("models/trained")
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_config = {
            'min_samples': Config.ML_MIN_TRAINING_DATA or 1000,
            'val_split': 0.2,
            'test_split': 0.1,
            'retrain_interval_hours': Config.RETRAIN_INTERVAL_HOURS or 24,
            'model_types': ['random_forest', 'xgboost', 'lightgbm'],
            'symbols': [],
            'timeframes': ['5m', '15m', '1h'],
            'target_periods': 5,  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ 5 –ø–µ—Ä–∏–æ–¥–æ–≤ –≤–ø–µ—Ä–µ–¥
            'lookback_periods': 2000
        }
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_history = []
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self.model_configs = {
            'random_forest': {
                'class': RandomForestClassifier,
                'params': {
                    'n_estimators': 100,
                    'max_depth': 10,
                    'min_samples_split': 5,
                    'min_samples_leaf': 2,
                    'class_weight': 'balanced',
                    'n_jobs': -1,
                    'random_state': 42
                }
            },
            'xgboost': {
                'params': {
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'random_state': 42,
                    'eval_metric': 'mlogloss'
                }
            },
            'lightgbm': {
                'params': {
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'class_weight': 'balanced',
                    'random_state': 42,
                    'verbose': -1
                }
            }
        }
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞"""
        db = SessionLocal()
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ë–î
            if Config.TRADING_PAIRS:
                self.training_config['symbols'] = Config.TRADING_PAIRS
            else:
                # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–¥–µ–ª–æ–∫
                recent_trades = db.query(Trade.symbol).distinct().limit(50).all()
                self.training_config['symbols'] = [t[0] for t in recent_trades]
            
            if not self.training_config['symbols']:
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø–∞—Ä—ã
                self.training_config['symbols'] = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']
            
            self.logger.info(
                "ML Trainer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                category='ml',
                symbols=self.training_config['symbols'][:5],  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                total_symbols=len(self.training_config['symbols']),
                model_types=self.training_config['model_types']
            )
            
        finally:
            db.close()
    
    async def train_symbol_model(self, symbol: str, timeframe: str = '5m') -> Dict[str, Any]:
        """
        –†–ï–ê–õ–¨–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        """
        try:
            self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}", category='ml', symbol=symbol)
            
            # === 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ===
            df = await self.feature_engineer.extract_features(
                symbol=symbol,
                timeframe=timeframe,
                lookback_periods=self.training_config['lookback_periods']
            )
            
            if df.empty:
                return {'success': False, 'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è'}
            
            X, y = self.feature_engineer.prepare_training_data(
                df,
                target_type='direction',
                target_periods=self.training_config['target_periods']
            )
            
            if len(X) < self.training_config['min_samples']:
                return {
                    'success': False,
                    'error': f'–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(X)} < {self.training_config["min_samples"]}'
                }
            
            # === 2. –í–†–ï–ú–ï–ù–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–• ===
            # –í–∞–∂–Ω–æ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤!
            test_size = int(len(X) * self.training_config['test_split'])
            X_temp, X_test = X[:-test_size], X[-test_size:]
            y_temp, y_test = y[:-test_size], y[-test_size:]
            
            # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
            val_size = int(len(X_temp) * self.training_config['val_split'])
            X_train, X_val = X_temp[:-val_size], X_temp[-val_size:]
            y_train, y_val = y_temp[:-val_size], y_temp[-val_size:]
            
            self.logger.info(
                f"–î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è {symbol}",
                category='ml',
                train_size=len(X_train),
                val_size=len(X_val),
                test_size=len(X_test),
                class_distribution=y_train.value_counts().to_dict()
            )
            
            # === 3. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô ===
            trained_models = {}
            results = {}
            
            # Random Forest (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            try:
                rf_config = self.model_configs['random_forest']
                rf_model = rf_config['class'](**rf_config['params'])
                rf_model.fit(X_train, y_train)
                trained_models['random_forest'] = rf_model
                
                # –û—Ü–µ–Ω–∫–∞
                results['random_forest'] = await self._evaluate_model(
                    rf_model, X_train, y_train, X_val, y_val, X_test, y_test
                )
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Random Forest: {e}", category='ml')
            
            # XGBoost (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            try:
                import xgboost as xgb
                xgb_config = self.model_configs['xgboost']
                xgb_model = xgb.XGBClassifier(**xgb_config['params'])
                xgb_model.fit(X_train, y_train)
                trained_models['xgboost'] = xgb_model
                
                results['xgboost'] = await self._evaluate_model(
                    xgb_model, X_train, y_train, X_val, y_val, X_test, y_test
                )
                
            except ImportError:
                self.logger.warning("XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", category='ml')
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è XGBoost: {e}", category='ml')
            
            # LightGBM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            try:
                import lightgbm as lgb
                lgb_config = self.model_configs['lightgbm']
                lgb_model = lgb.LGBMClassifier(**lgb_config['params'])
                lgb_model.fit(X_train, y_train)
                trained_models['lightgbm'] = lgb_model
                
                results['lightgbm'] = await self._evaluate_model(
                    lgb_model, X_train, y_train, X_val, y_val, X_test, y_test
                )
                
            except ImportError:
                self.logger.warning("LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", category='ml')
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è LightGBM: {e}", category='ml')
            
            if not trained_models:
                return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏'}
            
            # === 4. –°–û–ó–î–ê–ù–ò–ï –ê–ù–°–ê–ú–ë–õ–Ø ===
            # –í–µ—Å–∞ –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            weights = []
            for model_name in trained_models.keys():
                weights.append(results[model_name]['val_accuracy'])
            
            ensemble = EnsembleModel(
                models=trained_models,
                weights=weights,
                name=f"{symbol}_ensemble"
            )
            ensemble.feature_columns = df.columns.tolist()
            
            # –û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
            ensemble_results = await self._evaluate_model(
                ensemble, X_train, y_train, X_val, y_val, X_test, y_test
            )
            results['ensemble'] = ensemble_results
            
            # === 5. –í–´–ë–û–† –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò ===
            best_model_name = max(results.keys(), key=lambda k: results[k]['val_accuracy'])
            best_single_model = trained_models.get(best_model_name, list(trained_models.values())[0])
            
            # === 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò ===
            model_data = {
                'ensemble': ensemble,
                'best_single': best_single_model,
                'trained_models': trained_models,
                'feature_columns': df.columns.tolist(),
                'results': results,
                'training_config': self.training_config,
                'training_date': datetime.utcnow().isoformat(),
                'symbol': symbol,
                'timeframe': timeframe,
                'data_info': {
                    'train_size': len(X_train),
                    'val_size': len(X_val),
                    'test_size': len(X_test),
                    'feature_count': len(df.columns)
                }
            }
            
            model_path = self.models_dir / f"{symbol}_{timeframe}_model.pkl"
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
            self.models[f"{symbol}_{timeframe}"] = ensemble
            
            # === 7. –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–û–í ===
            await self.generate_symbol_report(symbol, timeframe, results, model_data)
            
            self.logger.info(
                f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è {symbol} –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞",
                category='ml',
                symbol=symbol,
                best_model=best_model_name,
                best_accuracy=f"{results[best_model_name]['val_accuracy']:.3f}",
                ensemble_accuracy=f"{results['ensemble']['val_accuracy']:.3f}"
            )
            
            return {
                'success': True,
                'symbol': symbol,
                'timeframe': timeframe,
                'best_model': best_model_name,
                'ensemble_accuracy': results['ensemble']['test_accuracy'],
                'models_trained': list(trained_models.keys()),
                'results': {k: {metric: v for metric, v in v.items() if metric not in ['model']} 
                           for k, v in results.items()},
                'model_path': str(model_path)
            }
            
        except Exception as e:
            self.logger.error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}: {e}",
                category='ml',
                symbol=symbol,
                error=str(e)
            )
            return {'success': False, 'error': str(e)}
    
    async def _evaluate_model(self, model, X_train, y_train, X_val, y_val, X_test, y_test):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –≤—ã–±–æ—Ä–∫–∞—Ö"""
        try:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            train_pred = model.predict(X_train)
            val_pred = model.predict(X_val)
            test_pred = model.predict(X_test)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            return {
                'train_accuracy': accuracy_score(y_train, train_pred),
                'val_accuracy': accuracy_score(y_val, val_pred),
                'test_accuracy': accuracy_score(y_test, test_pred),
                'test_precision': precision_score(y_test, test_pred, average='weighted', zero_division=0),
                'test_recall': recall_score(y_test, test_pred, average='weighted', zero_division=0),
                'test_f1': f1_score(y_test, test_pred, average='weighted', zero_division=0),
                'model': model
            }
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏: {e}", category='ml')
            return {
                'train_accuracy': 0, 'val_accuracy': 0, 'test_accuracy': 0,
                'test_precision': 0, 'test_recall': 0, 'test_f1': 0,
                'model': model
            }
    
    async def train_all_models(self) -> Dict[str, Any]:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        self.logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –º–∞—Å—Å–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", category='ml')
        
        all_results = {}
        successful_models = 0
        
        for symbol in self.training_config['symbols']:
            try:
                result = await self.train_symbol_model(symbol)
                all_results[symbol] = result
                
                if result.get('success'):
                    successful_models += 1
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ–±—É—á–µ–Ω–∏—è–º–∏
                await asyncio.sleep(1)
                
            except Exception as e:
                self.logger.error(
                    f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {symbol}: {e}",
                    category='ml',
                    symbol=symbol
                )
                all_results[symbol] = {'success': False, 'error': str(e)}
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_symbols = len(self.training_config['symbols'])
        success_rate = successful_models / total_symbols if total_symbols > 0 else 0
        
        summary = {
            'timestamp': datetime.utcnow().isoformat(),
            'total_symbols': total_symbols,
            'successful_models': successful_models,
            'success_rate': success_rate,
            'results': all_results
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        self.training_history.append(summary)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        await self.generate_training_summary(summary)
        
        self.logger.info(
            f"‚úÖ –ú–∞—Å—Å–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ",
            category='ml',
            successful_models=successful_models,
            total_symbols=total_symbols,
            success_rate=f"{success_rate:.1%}"
        )
        
        return summary
    
    async def predict(self, symbol: str, current_data: Optional[pd.DataFrame] = None,
                     timeframe: str = '5m', use_ensemble: bool = True) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        try:
            model_key = f"{symbol}_{timeframe}"
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ø–∞–º—è—Ç–∏
            if model_key not in self.models:
                # –ó–∞–≥—Ä—É–∑–∫–∞ —Å –¥–∏—Å–∫–∞
                model_path = self.models_dir / f"{symbol}_{timeframe}_model.pkl"
                if not model_path.exists():
                    return {
                        'success': False,
                        'error': f'–ú–æ–¥–µ–ª—å –¥–ª—è {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–µ–Ω–∏–µ.'
                    }
                
                with open(model_path, 'rb') as f:
                    model_data = pickle.load(f)
                
                model_to_use = model_data['ensemble'] if use_ensemble else model_data['best_single']
                self.models[model_key] = model_to_use
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç –º–æ–¥–µ–ª–∏
                training_date = datetime.fromisoformat(model_data['training_date'])
                model_age_hours = (datetime.utcnow() - training_date).total_seconds() / 3600
                
                if model_age_hours > self.training_config['retrain_interval_hours']:
                    self.logger.warning(
                        f"–ú–æ–¥–µ–ª—å –¥–ª—è {symbol} —É—Å—Ç–∞—Ä–µ–ª–∞",
                        category='ml',
                        symbol=symbol,
                        age_hours=model_age_hours
                    )
            
            model = self.models[model_key]
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if current_data is None:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
                features_df = await self.feature_engineer.extract_features(
                    symbol=symbol,
                    timeframe=timeframe,
                    lookback_periods=100  # –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                )
                
                if features_df.empty:
                    return {'success': False, 'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è'}
                
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
                X = features_df.iloc[-1:].values
            else:
                X = current_data.values
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = model.predict(X)[0]
            prediction_proba = model.predict_proba(X)[0]
            confidence = model.get_confidence(X)[0] if hasattr(model, 'get_confidence') else max(prediction_proba)
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
            direction_map = {-1: 'SELL', 0: 'HOLD', 1: 'BUY'}
            direction = direction_map.get(prediction, 'HOLD')
            
            result = {
                'success': True,
                'symbol': symbol,
                'direction': direction,
                'confidence': float(confidence),
                'prediction_value': int(prediction),
                'probabilities': {
                    'bearish': float(prediction_proba[0]) if len(prediction_proba) > 0 else 0.0,
                    'neutral': float(prediction_proba[1]) if len(prediction_proba) > 1 else 0.0,
                    'bullish': float(prediction_proba[2]) if len(prediction_proba) > 2 else 0.0
                },
                'model_type': 'ensemble' if use_ensemble else 'single',
                'timestamp': datetime.utcnow().isoformat()
            }
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if confidence > 0.7:
                self.logger.info(
                    f"–°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª ML –¥–ª—è {symbol}",
                    category='ml',
                    symbol=symbol,
                    direction=direction,
                    confidence=f"{confidence:.3f}"
                )
            
            return result
            
        except Exception as e:
            self.logger.error(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {symbol}: {e}",
                category='ml',
                symbol=symbol,
                error=str(e)
            )
            return {'success': False, 'error': str(e)}
    
    async def generate_symbol_report(self, symbol: str, timeframe: str, 
                                   results: Dict, model_data: Dict):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ –æ–±—É—á–µ–Ω–∏—é —Å–∏–º–≤–æ–ª–∞"""
        try:
            report = {
                'symbol': symbol,
                'timeframe': timeframe,
                'timestamp': datetime.utcnow().isoformat(),
                'training_info': model_data['data_info'],
                'model_performance': {
                    name: {k: v for k, v in metrics.items() if k != 'model'}
                    for name, metrics in results.items()
                },
                'best_model': max(results.keys(), key=lambda k: results[k]['val_accuracy']),
                'ensemble_vs_best': {
                    'ensemble_accuracy': results['ensemble']['test_accuracy'],
                    'best_single_accuracy': max(
                        results[k]['test_accuracy'] for k in results.keys() if k != 'ensemble'
                    ),
                    'improvement': results['ensemble']['test_accuracy'] - max(
                        results[k]['test_accuracy'] for k in results.keys() if k != 'ensemble'
                    )
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            report_path = self.reports_dir / f"{symbol}_{timeframe}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_path, 'w') as f:
                json.dump(report, f, indent=2)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –¥–ª—è {symbol}: {e}", category='ml')
    
    async def generate_training_summary(self, summary: Dict):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—â–∏–π –æ—Ç—á–µ—Ç –ø–æ –º–∞—Å—Å–æ–≤–æ–º—É –æ–±—É—á–µ–Ω–∏—é"""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            successful_results = {k: v for k, v in summary['results'].items() if v.get('success')}
            
            if successful_results:
                accuracies = [r.get('ensemble_accuracy', 0) for r in successful_results.values()]
                performance_summary = {
                    'mean_accuracy': np.mean(accuracies),
                    'median_accuracy': np.median(accuracies),
                    'best_accuracy': max(accuracies),
                    'worst_accuracy': min(accuracies),
                    'std_accuracy': np.std(accuracies)
                }
            else:
                performance_summary = {'error': '–ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'}
            
            # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
            full_summary = {
                **summary,
                'performance_summary': performance_summary,
                'failed_symbols': [k for k, v in summary['results'].items() if not v.get('success')],
                'training_config': self.training_config
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            summary_path = self.reports_dir / f"training_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(summary_path, 'w') as f:
                json.dump(full_summary, f, indent=2)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}", category='ml')
    
    async def auto_retrain_loop(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ü–∏–∫–ª –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üîÑ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ü–∏–∫–ª–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è", category='ml')
        
        while True:
            try:
                self.logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–ª–∞–Ω–æ–≤–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ", category='ml')
                
                # –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
                results = await self.train_all_models()
                
                # –ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                success_rate = results['success_rate']
                if success_rate < 0.5:
                    self.logger.warning(
                        f"–ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {success_rate:.1%}",
                        category='ml'
                    )
                
                # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
                interval_hours = self.training_config['retrain_interval_hours']
                self.logger.info(
                    f"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–ª–µ–¥—É—é—â–µ–µ —á–µ—Ä–µ–∑ {interval_hours}—á",
                    category='ml',
                    success_rate=f"{success_rate:.1%}"
                )
                
                await asyncio.sleep(interval_hours * 3600)
                
            except Exception as e:
                self.logger.error(
                    f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}",
                    category='ml',
                    error=str(e)
                )
                # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∂–¥–µ–º —á–∞—Å –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                await asyncio.sleep(3600)
    
    def get_model_info(self, symbol: str, timeframe: str = '5m') -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        try:
            model_path = self.models_dir / f"{symbol}_{timeframe}_model.pkl"
            if not model_path.exists():
                return {'exists': False}
            
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            training_date = datetime.fromisoformat(model_data['training_date'])
            age_hours = (datetime.utcnow() - training_date).total_seconds() / 3600
            
            return {
                'exists': True,
                'symbol': symbol,
                'timeframe': timeframe,
                'training_date': model_data['training_date'],
                'age_hours': age_hours,
                'models_included': list(model_data['trained_models'].keys()),
                'performance': model_data['results']['ensemble']['test_accuracy'],
                'data_size': model_data['data_info']['train_size'],
                'feature_count': model_data['data_info']['feature_count']
            }
            
        except Exception as e:
            return {'exists': False, 'error': str(e)}
    
    def list_available_models(self) -> List[Dict[str, Any]]:
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        models = []
        for model_file in self.models_dir.glob("*.pkl"):
            try:
                # –ü–∞—Ä—Å–∏–º –∏–º—è —Ñ–∞–π–ª–∞
                parts = model_file.stem.split('_')
                if len(parts) >= 3:
                    symbol = '_'.join(parts[:-2])
                    timeframe = parts[-2]
                    
                    model_info = self.get_model_info(symbol, timeframe)
                    if model_info.get('exists'):
                        models.append(model_info)
            except:
                continue
        
        return sorted(models, key=lambda x: x.get('age_hours', float('inf')))


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Ç—Ä–µ–Ω–µ—Ä–∞
ml_trainer = MLTrainer()

# –≠–∫—Å–ø–æ—Ä—Ç
__all__ = ['MLTrainer', 'EnsembleModel', 'ml_trainer']